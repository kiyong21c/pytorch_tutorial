{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiyong21c/pytorch_tutorial/blob/main/20220704_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 활용\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x \n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "# 모델에 사용될 데이터는 2차원 이어야함\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32) \n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32) \n",
        "\n",
        "n_samples, n_features = X.shape # torch.Size([4, 1])\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32) # X_test.shape : torch.Size([1]) 넘파이랑 다른 형식\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "# 입력노드 1개 출력노드 1개로 연결된 간단한 모델\n",
        "# 입력노드에 X값들이 하나씩 줄지어 들어가는 모양\n",
        "input_size = n_features # 1\n",
        "output_size = n_features # 1\n",
        "\n",
        "# we can call this model with samples X\n",
        "model = nn.Linear(input_size, output_size) # 모델생성(torch.nn에서 제공해줌)\n",
        "\n",
        "'''\n",
        "nn.Module을 상속받아서 LinearRegression 모델 오버라이딩하는 방법\n",
        "class LinearRegression(nn.Module): \n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "model = LinearRegression(input_size, output_size)\n",
        "'''\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}') # 출력할때 마다 다른값\n",
        "# model(X_test) : tensor([4.1130], grad_fn=<AddBackward0>)\n",
        "# model(X_test).item() : 4.113\n",
        "\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss() # 모델을 통해 나온값과 실제값의 차이를 MSE 방식으로 처리하겠다\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # 모델의 파라미터(w, b)를 갱신/관리를 SGD 방식으로 하겠다\n",
        "# list(model.parameters()) : [Parameter containing : tensor([[-0.0085]], requires_grad=True), Parameter containing : tensor([-0.9986], requires_grad=True)]\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights(with torch.no_grad(): 하지 않아도 됨)\n",
        "    optimizer.step() # w, b 갱신\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad() # dloss/dw, dloss/db 초기화(0)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters() # 1)제너레이터를 변수에 나눠서 할당하거나, 2)list화 하거나\n",
        "        print(f'epoch : {epoch+1},  w = {w[0].item():.3f},  b = {b[0].item():.3f},  loss = {l.item():.3f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "id": "_RnlyRLBo792",
        "outputId": "918faa29-7548-450d-deae-81ba2d4a6cef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#samples: 4, #features: 1\n",
            "Prediction before training: f(5) = -4.418\n",
            "epoch : 1,  w = -0.277,  b = -0.641,  loss = 67.125\n",
            "epoch : 11,  w = 1.601,  b = -0.006,  loss = 1.739\n",
            "epoch : 21,  w = 1.904,  b = 0.093,  loss = 0.047\n",
            "epoch : 31,  w = 1.953,  b = 0.106,  loss = 0.003\n",
            "epoch : 41,  w = 1.962,  b = 0.106,  loss = 0.002\n",
            "epoch : 51,  w = 1.965,  b = 0.103,  loss = 0.002\n",
            "epoch : 61,  w = 1.966,  b = 0.100,  loss = 0.002\n",
            "epoch : 71,  w = 1.967,  b = 0.097,  loss = 0.002\n",
            "epoch : 81,  w = 1.968,  b = 0.094,  loss = 0.001\n",
            "epoch : 91,  w = 1.969,  b = 0.092,  loss = 0.001\n",
            "Prediction after training: f(5) = 9.938\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Colaboratory에 오신 것을 환영합니다",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}